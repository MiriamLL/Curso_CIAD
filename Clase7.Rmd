---
title: "Clase 7"
subtitle: "Exploracion y <br> modelo lineal"
author: "Miriam Lerma"
date: "Marzo 2021"
output:
  xaringan::moon_reader:
    css: ["default"]
    seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      
---
```{r metathis, include = FALSE}
#Con esta libreria puedo poner informacion que saldra en el titulo, en los buscadores y demas, como de titulo y fechas. Asi como elegir la imagen que saldra de inicio.

library(metathis)
meta() %>%
  meta_name("github-repo" = "MiriamLL/Curso_CIAD") %>%
  meta_social(
    title = "Cargar datps",
    description = paste0(
      "Introduccion a RStudio",
      "Curso de R"),
    url = "https://github.com/MiriamLL/Curso_CIAD/blob/main/Clase3Parte1.html",
    image = "https://images.unsplash.com/photo-1525909002-1b05e0c869d8?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=675&q=80",
    image_alt = paste0(
      "Introduccion a R y RStudio",
      "Curso de R"),
    og_type = "website",
    og_author = "Miriam Lerma",
    twitter_card_type = "summary_large_image",
    twitter_creator = "@MiriamLL",
    twitter_site = "@MiriamLL")
```

```{r include = FALSE}
#Paquetes
library(xaringanExtra)
```

class: title-slide, inverse, middle, right
background-image: url(https://images.unsplash.com/photo-1612343267903-f6c1b17e6e1c?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=667&q=80)
background-size: cover

### `r rmarkdown::metadata$title`
# `r rmarkdown::metadata$subtitle`

**`r rmarkdown::metadata$author`**<br>
`r rmarkdown::metadata$date`

---

# Intro

La clase es de 2 horas.

- Exploracion de datos  
- Modelos lineales


```{r, echo=FALSE,include=FALSE, message=FALSE}
library(emo)
library(here)
library(fontawesome)
library(ggplot2)
```

--

## Ustedes

- Conocimientos de R (saben abrirlo, cargar paquetes y datos, saben hacer operaciones y graficos).  

- Quieren conocer explorar datos y conocer la sintaxis para hacer modelos lineales en R.  

--

<br>

 **Notas** <br>
Ya vieron teoria, hoy es solo para que practiquen en R. <br>
Recuerden que los modelos dependen de sus preguntas y experimentos o muestreos.  

---

# Créditos & materiales:  

- Ejercicios de estadística con R <br> 
[Matias Andina](https://bookdown.org/matiasandina/R-intro/modelos-lineales.html)

- Ejemplos de regresiones lineales simples <br>
[Sthda por Alboukadel Kassambara](http://www.sthda.com/english/articles/40-regression-analysis/167-simple-linear-regression-in-r/)`r emo::ji("star")` 

- Libro <br> 
[Handbook of Regression Models in People Analytics](http://peopleanalytics-regression-book.org/)  

- Tutoriales diversos <br> 
[STAT 545](https://stat545.com/)

- Ejercicios practicos <br> 
[ourcodingclub](https://ourcodingclub.github.io/tutorials/mixed-models/)

- Outliers <br> 
[Rocio Joo](https://github.com/rociojoo)

- Imágenes adicionales <br> 
[Unsplash](https://unsplash.com/)


---

class: title-slide, inverse, bottom
background-image: url(https://images.unsplash.com/photo-1516478784322-0b77268e6c64?ixid=MXwxMjA3fDB8MHxzZWFyY2h8Mjh8fGRvdHN8ZW58MHx8MHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=500&q=60)
background-size: cover


# Exploración

---

# 1.1. Inspecciona

**Siempre inspecciona tus datos!** <br>
Todos esto [graficos]("https://raw.githubusercontent.com/stephlocke/lazyCDN/master/DinoSequential.gif) tienen medias, desviaciones estandar y una correlacion entre puntos similar. 


```{r echo=FALSE, out.height=350}
knitr::include_graphics("https://raw.githubusercontent.com/stephlocke/lazyCDN/master/DinoSequential.gif")
```

---

## 1.1. Inspecciona

Alberto Cairo creo este paquete (datasauRus) para ilustrarlo.  

.pull-left[
Si quieren replicar algunas graficas:  
```{r, warning=FALSE}
#install.packages('datasauRus')
library(datasauRus)
```

```{r, fig.heigth=2, warning=FALSE, message=FALSE, echo=TRUE, eval=FALSE}
ggplot(datasaurus_dozen,
       aes(x=x, y=y, 
           colour=dataset))+
  geom_point()+ 
  theme_void()+ 
  theme(legend.position = "none")+
  facet_wrap(~dataset, ncol=3)
```
]

.pull-right[
```{r, fig.heigth=2, warning=FALSE, message=FALSE, echo=FALSE, out.width="90%"}
ggplot(datasaurus_dozen,aes(x=x, y=y, colour=dataset))+
  geom_point()+ theme_void()+ theme(legend.position = "none")+
  facet_wrap(~dataset, ncol=3)
```
]

---

# 1.2. Pinguinos
Exploremos los datos de pinguinos.

```{r}
library(ggplot2)
library(datos)
Pingus<-datos::pinguinos
```

.center[
```{r echo=FALSE, out.height=300}
knitr::include_graphics("https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/man/figures/lter_penguins.png")
```
]

---

# 1.2. Pinguinos
Recordemos como se realizan los graficos de puntos. 

.pull-left[
```{r first-plot1b, eval=FALSE}
ggplot(Pingus) +
  aes(x = largo_aleta_mm, 
      y = masa_corporal_g)+
  geom_point()#<<
```
]

.pull-right[
```{r first-plot1b-out, ref.label='first-plot1b', warning=FALSE,echo=FALSE, out.width="80%"}
```
]

---

# 1.2. Pinguinos
Sabemos que hay tres especies, separemos las especies por colores.

.pull-left[
```{r plot02, eval=FALSE}
ggplot(Pingus, 
       aes(x=largo_aleta_mm, 
           y=masa_corporal_g, 
           color=especie))+ #<<
  geom_point()
```
]

.pull-right[
```{r plot02-out, ref.label='plot02', warning=FALSE,echo=FALSE, out.width="80%"}
```
]


---

# 1.2. Pinguinos
Si agregamos una nueva capa con la linea de tendencia, especificamos un ajuste lineal ("lm") podemos ver como se relacionan estos datos.  
No obstante! tenemos datos de tres especies diferentes!  

.pull-left[
```{r plot03, eval=FALSE}
ggplot(Pingus, 
       aes(x=largo_aleta_mm, 
           y=masa_corporal_g)) +
       geom_point(aes(color =especie))+ #<<
       geom_smooth(method="lm")
```
]

.pull-right[
```{r plot03-out, ref.label='plot03', warning=FALSE,message=FALSE, echo=FALSE, out.width="80%"}
```
]


---

# 1.2. Pinguinos
Cambiando algunos argumentos nos permite explorar y obtener diferentes resultados graficos usando los mismos datos.  
Por ejemplo, si cambiamos la ubicacion del color, le decimos que me haga lineas por especies.

.pull-left[
```{r plot04, eval=FALSE}
ggplot(Pingus, 
       aes(x=largo_aleta_mm, 
           y=masa_corporal_g, 
           color = especie)) +
       geom_point() +
       geom_smooth(method = "lm") #<<
```
]

.pull-right[
```{r plot04-out, ref.label='plot04', warning=FALSE,echo=FALSE, message=FALSE, out.width="80%"}
```
]

---

# 1.3. facet_wrap 

**face_wrap** es un argumento que nos permite ver variables categoricas separadas por panel. 

.pull-left[
```{r plot05, eval=FALSE}
ggplot(Pingus, 
       aes(x=largo_pico_mm, 
           y=alto_pico_mm)) +
  geom_point()+
  facet_wrap(~especie) #<<
```
]

.pull-right[
```{r plot05-out, ref.label='plot05', warning=FALSE,echo=FALSE, out.width="80%"}
```
]

---

class: title-slide, inverse, bottom
background-image: url(https://images.unsplash.com/photo-1516478784322-0b77268e6c64?ixid=MXwxMjA3fDB8MHxzZWFyY2h8Mjh8fGRvdHN8ZW58MHx8MHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=500&q=60)
background-size: cover


# Ejercicios

---

# 1. 4. Ejercicios juntos
```{r, warning=FALSE, message=FALSE}
library(datos)
library(tidyverse)
Pingus<-datos::pinguinos
```

Exploremos los datos usando solo los datos de Pinguinos de Adelia.
```{r}
Adelia<-Pingus%>%
  filter(especie=='Adelia') #<<
```

```{r echo=FALSE, out.height=200}
knitr::include_graphics("https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/man/figures/lter_penguins.png")
```

---

# 1. 4. Ejercicios juntos
Grafico de puntos.  
```{r, fig.heigth=2, warning=FALSE, message=FALSE, out.width="40%"}
p1 <- ggplot(Adelia, aes(x=largo_aleta_mm, y=masa_corporal_g)) +
       geom_point() #<<
p1
```

---

# 1. 4. Ejercicios juntos

Boxplot.  
```{r, fig.heigth=2, warning=FALSE, message=FALSE, out.width="40%"}
p2 <- ggplot(Adelia, aes(largo_aleta_mm, masa_corporal_g)) +
       geom_boxplot() #<<
p2
```

---

# 1. 4. Ejercicios juntos

Violin.   

```{r, fig.heigth=2, warning=FALSE, message=FALSE, out.width="40%"}
p3 <- ggplot(Adelia, aes(largo_aleta_mm, masa_corporal_g)) +
       geom_violin() #<<
p3
```

---

# 1. 4. Ejercicios juntos

Subamos un poco el nivel. 
Combinando boxplot y violin.  
Hagamos un plot compuesto y cambiemos los [colores](https://coolors.co/palettes/trending).  

```{r, fig.heigth=2, warning=FALSE, message=FALSE, out.width="40%"}
p4 <- ggplot(Adelia, aes(largo_aleta_mm, masa_corporal_g)) +
       geom_violin(fill='#e76f51', alpha=0.5)+ #<<
       geom_boxplot(color="#e76f51", fill="#e9c46a",#<<
                    lwd=0.8, width=0.2 )
p4
```

---

# 1.4. facet_wrap 

Ver variables categoricas separadas por panel. 

```{r, warning=FALSE, message=FALSE, out.height="10%"}
ggplot(Pingus, aes(largo_pico_mm, alto_pico_mm)) +
  geom_point()+
  facet_wrap(~especie) #<<
```

---

# 1.4. cowplot

Noten que al usar **facet_wrap** los paneles se acomodan de cierta manera que no es facil de cambiar, para cambiar como estan acomodados podemos usar **cowplot** o **patchwork**.  

Deben instalarlo antes.
```{r}
#install.packages("cowplot")
library(cowplot)
```

---

# 1.4. cowplot

Elegir el orden.  
Noten que les van a salir muchos warning por que hay NAs en nuestro data frame.
```{r, fig.heigth=2, warning=FALSE, message=FALSE, out.width="40%"}
cowplot::plot_grid(p1,p2,p3,p4, #Estos son los plots que crearon antes
                   labels = "AUTO") #<< Agrega letras
```


---

class: title-slide, inverse, bottom
background-image: url(https://images.unsplash.com/photo-1599599810769-bcde5a160d32?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1489&q=80)
background-size: cover

# Modelos lineales

---

# 2. Modelos lineales

Recordatorio: 

- La realidad es multidimensional, compleja e incierta.  
- Un modelo es una representación formal de un fenómeno, una reducción de dimensionalidad que posee utilidad práctica.  
- Dicha representación normalmente puede ser condensada en una expresión matemática, una fórmula, que indica cómo una variable se relaciona con otra(s). 
- Empíricamente, el paradigma se basa en estudiar la relación matemática entre variables aleatorias respuesta, con una distribución de probabilidades dada, y aquellas variables que la predicen, con el fin de explicar asociaciones entre variables y realizar inferencia.


---

## 2.1. Generar datos

Cuando busquen ejemplos estadisticos en internet, en algun momento van a toparse con:
```{r}
set.seed(123)
ejemplo <- rnorm(n = 10000, mean = 0, sd = 1)
```

Que es **set.seed**?  
**set.seed** genera secuencias de numeros "random" pero al poner una "semilla" nos aseguramos de que nos genere la misma secuencia en todas las computadoras.

Que es **rnorm**?  
**rnorm** sirve para generar muestras aleatorias a partir de una población teórica con distribución normal, dandole media y desviación estándar.

--

Cuando hagan preguntas en internet, es muy util usarlo! 

---

## 2.2. Ejemplo practico

### Chocolate y felicidad

-  Supongamos que podemos medir felicidad de manera cuantitativa, como una variable continua.  
- Supongamos, además, que nuestro laboratorio quiere investigar cómo impactan distintas dosis de chocolate a la felicidad de los humanos. 

.center[
```{r echo=FALSE, out.height=300}
knitr::include_graphics("https://images.unsplash.com/photo-1553452118-621e1f860f43?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=634&q=80")
```
]

---

## 2.2. Chocolate y felicidad
Para esto, tomamos una muestra de **100 voluntarios** y los asignamos de manera aleatoria a **5 dosis de chocolate (20, 40, 60, 80, y 100 gramos)**. Los individuos consumen la dosis asignada, el chocolate aumenta su felicidad (según la fórmula felicidad=dosis∗2.5+10), que medimos y graficamos.

Generar participantes
```{r}
id <- 1:100
```

Generar dosis
```{r}
dosis <- sort(rep(seq(20,100,20), 20))
```

Generar respuesta "ideal"
```{r}
respuesta <- dosis * 2.5 + 10
```

Construir data.frame
```{r}
datos <- data.frame(id=id,dosis=dosis,respuesta=respuesta)
```

---

## 2.3. Chocolate y felicidad
Asi se veria nuestro modelo **ideal**

.pull-left[
```{r plot10, eval=FALSE}
p <- ggplot(datos, 
            aes(x=dosis, 
                y=respuesta))+
      geom_point()+
      xlab("Dosis Chocolate (gr)")+
      ylab("Felicidad")
p
```
]


.pull-right[
```{r plot10-out, ref.label='plot10', warning=FALSE,echo=FALSE, message=FALSE, out.width="80%"}
```
]


---

# 2.4. Chocolate y felicidad

- Pero, en la realidad, esperamos variabilidad en la respuesta al chocolate entre individuos.  
- Si queremos trabajar con un modelo **más realista** deberíamos tener mas variacion en la respuesta:

Semilla para muestras aleatorias.
```{r}
set.seed(444)
```

Agregar ruido con distribucion normal (media 0, sd = 5)
```{r}
datos$respuesta <- datos$respuesta + rnorm(n = 100, mean = 0, sd = 5)
```

---

# 2.4. Chocolate y felicidad

- Modelo un poco **más** realista, la respuesta muestra variaciones.

.pull-left[
```{r plot11, eval=FALSE}
p <- ggplot(datos, 
            aes(x=dosis, 
                y=respuesta))+
       geom_point(alpha = 0.1)+
       xlab("Dosis Chocolate (gr)")+
       ylab("Felicidad")
p
```
]

.pull-right[
```{r plot11-out, ref.label='plot11', warning=FALSE,echo=FALSE, message=FALSE, out.width="80%"}
```
]


---

# 2.5. Chocolate y felicidad
Entre mayor dosis de chocolate más valor de felicidad.  

- ¿Cuál es el valor esperado de felicidad para una dada dosis de chocolate?  
- ¿Cómo podemos estimarlo?  

.center[
```{r echo=FALSE, out.height=300}
knitr::include_graphics("https://images.unsplash.com/photo-1553452118-621e1f860f43?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=634&q=80")
```
]

---

# 2.6. Modelo lineal

Para construir modelos en R, es importante el simbolo *virgulilla*
```{r, eval=FALSE} 
~  
```

En nuestro caso, queremos estudiar la relación entre la felicidad (respuesta) y la dosis de chocolate (dosis).
Entonces el modelo se construiria de la siguiente manera.

```{r}
modelo_chocolate <- lm(data=datos,
                       respuesta ~ dosis)
```

---

# 2.6. summary
Ver resultados del modelo.
```{r}
summary(modelo_chocolate)
```

---

# 2.7. Broom

El paquete broom (de la paqueteria tidyverse), nos permite extraer información estadística de los modelos. 

Aquí está la tabla con los estimadores:
```{r}
broom::tidy(modelo_chocolate)
```

A partir de la columna de estimadores (estimate), vemos que el consumo de chocolate incrementa la felicidad (esperamos mayor un incremento en ~2.52 unidades de felicidad por cada gramo de chocolate).  

Nuestro modelo puede escribirse como:

**felicidad=2.52∗dosis+8.59**

---

# 2.8. Recordatorio

**felicidad=2.52∗dosis+8.59**

```{r echo=FALSE, out.height=300}
knitr::include_graphics("https://datascience.foundation/img/pdf_images/understanding_of_linear_regression_with_python_1.png")
```

---

# 2.9. Coeficientes.

También podemos acceder a porciones del modelo por separado. 

Coeficientes.  
```{r}
modelo_chocolate$coefficients
```

---

# 2.9. Intervalos.

Intervalos. 
```{r}
round(confint(modelo_chocolate), 3) 
```

Valores predichos.  
```{r}
head(modelo_chocolate$fitted.values,5)
```

Residuales.
```{r}
head(modelo_chocolate$residuals,5)
```

---

## 2.10. Supuestos

Podemos explorar el ajuste y analizar el cumplimiento de supuestos en R utilizando la función plot que maneja bien objetos lm.

.pull-left[
```{r plot13, eval=FALSE}
par(mfrow = c(2, 2))
plot(modelo_chocolate)
```
]

.pull-right[
```{r plot13-out, ref.label='plot13', warning=FALSE,echo=FALSE, message=FALSE, out.width="100%"}
```
]

---

## 2.11. Nuevo modelo

Cambiemos nuestros datos para un peor ajuste. 
```{r}
datos$nueva_dosis <- datos$dosis + rnorm(100,10,10)
```

Creemos un nuevo modelo.
```{r}
nuevo_modelo <- lm(data = datos,
                   respuesta~nueva_dosis)
```

Agreguemos los valores predichos y los residuales a nuestro data frame.
```{r}
datos$nuevo_pred <- nuevo_modelo$fitted.values
datos$residuos <- nuevo_modelo$residuals 
```

---

# 2.11. Nuevo modelo

Estos son nuestros nuevos datos, y la linea de regression. 

```{r, fig.heigth=2, warning=FALSE, message=FALSE, out.width="40%"}
Plot_nueva_dosis<- ggplot(datos, aes(nueva_dosis, respuesta))+
  geom_point()+
  geom_point(aes(nueva_dosis, nuevo_pred), color="gray50", pch=1) +
  theme(plot.background = element_rect(colour = NA))+
  xlab("Dosis Chocolate (gr)")+
  ylab("Felicidad")
Plot_nueva_dosis
```

---

## 2.11. Residuales

Agregar los residuales.
```{r, fig.heigth=2, warning=FALSE, message=FALSE, out.width="40%"}
Plot_nueva_dosis +
  geom_segment(aes(xend = nueva_dosis, #<<
                   yend = nuevo_pred), #<<
               alpha=0.5)
```

---

## 2.11. Residuales

Lo que nuestra regresión está realizando es minimizar la suma de los residuos al cuadrado.  
Una herramienta para visualizar mejor los puntos con residuos grandes es graficarlos utilizando una escala de color y tamaño.

.pull-left[
```{r plot14, eval=FALSE}
ggplot(datos, aes(nueva_dosis, respuesta))+
  geom_point(aes(color = residuos, size=abs(residuos)))+ 
  geom_point(aes(nueva_dosis, nuevo_pred), color="gray50", pch=1) +
  geom_segment(aes(xend = nueva_dosis, yend = nuevo_pred),
               alpha=0.5)+
  xlab("Dosis Chocolate (gr)")+
  ylab("Felicidad")+
  scale_color_gradientn(colours = c("red", "black", "red"))+
  guides(color = FALSE,
         size = FALSE)
```
]

.pull-right[
```{r plot14-out, ref.label='plot14', warning=FALSE,echo=FALSE, message=FALSE, out.width="80%"}
```
]

---

## 2.12. ¿Por qué hacer una regresión?

Los objetivos de realizar un análisis de regresión pueden resumirse en:

- Describir la relación funcional entre X e Y
- Determinar cuánta de la variación en Y puede ser explicada por la variación de X y cuánto permanece sin explicar.
- Estimar los parámetros del modelo.
- Hacer inferencia sobre los parámetros del modelo (mediante pruebas de hipótesis y cálculo de intervalos de confianza).

---

## 2.13 Ejercicios juntos

Modelo ideal.
```{r}
id <- 1:100 
dosis <- sort(rep(seq(20,100,20), 20))
respuesta <- dosis * 2.5 + 10
datos <- data.frame(id=id,
                    dosis=dosis,
                    respuesta=respuesta)
```

Explorar los datos.
```{r, fig.heigth=2, warning=FALSE, message=FALSE, eval=FALSE, out.width="40%"}
p <- ggplot(datos, 
            aes(x=dosis, y=respuesta))+
      geom_point()+
      xlab("Dosis Chocolate (gr)")+
      ylab("Felicidad")
p
```

---

## 2.14. Ejercicios juntos

Modelo con un poco mas realista.
```{r}
set.seed(444)
datos$respuesta <- datos$respuesta + rnorm(n = 100, mean = 0, sd = 5)
```

Explorar los datos.
```{r, fig.heigth=2, warning=FALSE, message=FALSE, eval=FALSE}
p <- ggplot(datos, 
            aes(x=dosis, y=respuesta))+
       geom_point(alpha = 0.1)+
       xlab("Dosis Chocolate (gr)")+
       ylab("Felicidad")
p
```

---

## 2.14. Ejercicios juntos

Sintaxis de modelos lineares.
```{r, eval=FALSE}
modelo_chocolate <- lm(data=datos,
                       respuesta ~ dosis)
```

Obtener estimadores.
```{r, eval=FALSE}
summary(modelo_chocolate)
broom::tidy(modelo_chocolate)
```

Ver coeficientes.
```{r, eval=FALSE}
modelo_chocolate$coefficients
```

Graficar
```{r, eval=FALSE}
ggplot(datos, aes(dosis, respuesta))+ geom_point(alpha = 0.1)+
       xlab("Dosis Chocolate (gr)")+ylab("Felicidad")+
  geom_smooth(method = "lm", color="lightgray", se=FALSE)+
  stat_summary(fun = mean, geom="point", size=2, color="red")
```

---

## 2.14. Ejercicios juntos

Cambiemos nuestros datos para un peor ajuste. 
```{r, eval=FALSE}
datos$nueva_dosis <- datos$dosis + rnorm(100,10,10)
```

```{r, eval=FALSE}
nuevo_modelo <- lm(data = datos,
                   respuesta~nueva_dosis)
```

```{r, eval=FALSE}
datos$nuevo_pred <- nuevo_modelo$fitted.values
datos$residuos <- nuevo_modelo$residuals 
```

```{r, eval=FALSE}
ggplot(datos, aes(nueva_dosis, respuesta))+
  geom_point(aes(color = residuos, size=abs(residuos)))+ 
  geom_point(aes(nueva_dosis, nuevo_pred), color="gray50", pch=1) +
  geom_segment(aes(xend = nueva_dosis, yend = nuevo_pred),
               alpha=0.5)+
  xlab("Dosis Chocolate (gr)")+
  ylab("Felicidad")+
  scale_color_gradientn(colours = c("red", "black", "red"))+
  guides(color = FALSE,
         size = FALSE)
```

---

class: title-slide, inverse, bottom
background-image: url(https://images.unsplash.com/photo-1476837579993-f1d3948f17c2?ixlib=rb-1.2.1&ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&auto=format&fit=crop&w=1350&q=80)
background-size: cover

# Outliers

---

## 3. Outliers

Un valor atípico (en inglés outlier) es una observación que es numéricamente distante del resto de los datos.
- Que hacer con ellos?

---

## 3. Outliers

Generemos datos.
```{r}
set.seed(42)
ex_data  = data.frame(x = 1:10,
                      y = 10:1 + rnorm(n = 10))
ex_model = lm(y ~ x, data = ex_data)
```

.pull-left[
```{r plot21, eval=FALSE}
ggplot(data = ex_data, 
       aes(x = x, 
           y = y)) +
  geom_smooth(data = ex_data, method = "lm", se = FALSE, aes(color = "inicial")) + 
  geom_smooth(method = "lm", se = FALSE, aes(color = "nuevo"), linetype = 2) + 
  scale_color_manual(name = "modelos", labels = c("inicial", "nuevo"), values = c("#56B4E9", "#E69F00")) +
theme_bw()
```
]

.pull-right[
```{r plot21-out, ref.label='plot21', warning=FALSE,echo=FALSE, message=FALSE, out.width="80%"}
```
]

---

## 3. Outliers

Añadamos un punto (x, y) y reajustemos una regresión lineal
```{r}
point_1 = c(5.4, 11) # nuevo punto
ex_data_1 = rbind(point_1, ex_data) 
model_1 = lm(y ~ x, data = ex_data_1) 
```


.pull-left[
```{r plot22, eval=FALSE}
ggplot(data = ex_data_1, aes(x = x, 
                             y = y)) +
  geom_point(color = "black") + # plotting all points
  geom_point(aes(x = x[1], y = y[1]), cex = 4, shape = 1) + # Denotar el nuevo punto
  geom_smooth(data = ex_data, method = "lm", # línea de regresión del modelo inicial
              se = FALSE, aes(color = "inicial")) + 
  geom_smooth(method = "lm", # línea de regresión del nuevo modelos
              se = FALSE, aes(color = "nuevo"), linetype = 2) + 
  scale_color_manual(name = "modelos", 
                     labels = c("inicial", "nuevo"), 
                     values = c("red", "blue")) +
theme_bw()
```
]

.pull-right[
```{r plot22-out, ref.label='plot22', warning=FALSE,echo=FALSE, message=FALSE, out.width="80%"}
```
]


---

## 3.2. Otro outlier

Creemos un nuevo punto, agreguemoslo al data frame y creemos un nuevo modelo.
```{r}
point_2 = c(18, -5.7) 
ex_data_2 = rbind(point_2, ex_data) 
model_2 = lm(y ~ x, data = ex_data_2) 
```

.pull-left[
```{r plot23, eval=FALSE}
ggplot(data = ex_data_2, aes(x = x, y = y)) +
  geom_point(color = "black") + # plotting all points
  geom_point(aes(x = x[1], y = y[1]), cex = 4, shape = 1) + # circunferencia para el nuevo punto
  geom_smooth(data = ex_data, method = "lm", se = FALSE, aes(color = "inicial")) + # línea de regresión del modelo inicial
  geom_smooth(method = "lm", se = FALSE, aes(color = "nuevo"), linetype = 2) + # línea de regresión del nuevo modelo
  scale_color_manual(name = "modelos", labels = c("inicial", "nuevo"), values = c("red", "blue")) +
theme_bw()
```
]

.pull-right[
```{r plot23-out, ref.label='plot23', warning=FALSE,echo=FALSE, message=FALSE, out.width="80%"}
```
]


---

## 3.3. Un ultimo outlier

Creemos un nuevo punto, agreguemoslo al data frame y creemos un nuevo modelo.
```{r}
point_3 = c(14, 5.1) 
ex_data_3 = rbind(point_3, ex_data) 
model_3 = lm(y ~ x, data = ex_data_3) 
```

El nuevo modelo parece bastante distinto.
.pull-left[
```{r plot24, eval=FALSE}
ggplot(data = ex_data_3, aes(x = x, y = y)) +
  geom_point(color = "black") + 
  geom_point(aes(x = x[1], y = y[1]), cex = 4, shape = 1) + #
  geom_smooth(data = ex_data, method = "lm", se = FALSE, aes(color = "inicial")) + 
  geom_smooth(method = "lm", se = FALSE, aes(color = "nuevo"), linetype = 2) + 
  scale_color_manual(name = "modelos", labels = c("inicial", "nuevo"), values = c("red", "blue")) +
theme_bw()
```
]

.pull-right[
```{r plot24-out, ref.label='plot24', warning=FALSE,echo=FALSE, message=FALSE, out.width="80%"}
```
]

---


class: title-slide, inverse, bottom
background-image: url(https://images.unsplash.com/photo-1612343267903-f6c1b17e6e1c?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=667&q=80)
background-size: cover


# Recapitulando

1.1. Explorar datos.  
1.2. Modelo lineal.

Siguiente clase:  
2.1. Objetos clase factor.  
2.2. Analisis de varianza.  


