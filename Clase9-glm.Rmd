---
title: "Clase 7"
subtitle: "Modelos mixtos"
author: "Miriam Lerma"
date: "Mayo 2021"
output:
  xaringan::moon_reader:
    css: RZero-themer.css
    seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      
---

```{r metathis, include = FALSE}
#Con esta libreria puedo poner informacion que saldra en el titulo, en los buscadores y demas, como de titulo y fechas. Asi como elegir la imagen que saldra de inicio.

library(metathis)
meta() %>%
  meta_name("github-repo" = "MiriamLL/Curso_CIAD") %>%
  meta_social(
    title = "Cargar datps",
    description = paste0(
      "Introduccion a RStudio",
      "Curso de R"),
    url = "https://github.com/MiriamLL/Curso_CIAD/blob/main/Clase3Parte1.html",
    image_alt = paste0(
      "Introduccion a R y RStudio",
      "Curso de R"),
    og_type = "website",
    og_author = "Miriam Lerma",
    twitter_card_type = "summary_large_image",
    twitter_creator = "@MiriamLL",
    twitter_site = "@MiriamLL")
```

```{r include = FALSE}
#Paquetes
library(xaringanExtra)
ColorLink<-"#219ebc"
ColorLinkInv<-"#f2cc8f"
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
``` 

```{r, echo=FALSE,include=FALSE, message=FALSE}
library(emo)
library(here)
library(fontawesome)
library(ggplot2)
```

class: title-slide, inverse, middle, right
background-image: url(https://images.unsplash.com/photo-1602264419088-8f8c7ab48489?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1267&q=80)
background-size: cover

### `r rmarkdown::metadata$title`
# `r rmarkdown::metadata$subtitle`

## `r rmarkdown::metadata$author`<br>
`r rmarkdown::metadata$date`

---

class: inverse

# Intro
- [Modelos mixtos](#lmer)
- [Incluir efectos aleatorios](#random_effects)
- [Incluir efectos anidados](#nested_effects)
- [AIC](#AIC)
- [Comparar modelos](#comparar)

--

#### Ustedes

- Conocimientos de R (saben abrirlo, cargar paquetes y datos, saben hacer operaciones y gráficos).  
- Quieren crear modelos mixtos en R y conocer la sintaxis.  
La clase de hoy esta en el [repositorio](https://github.com/MiriamLL/Prueba):
Clonen/Descarguen los materiales.  

#### Preguntas
Responder en el chat 💬
- Han visto modelos mixtos en artículos o tesis?
- Alguien ha escuchado que es el AIC?

---
class: inverse

## Créditos & Recursos

Lecturas
- [`r fa("book-open", fill = ColorLinkInv)` Intro por Gabriela Hajduk](https://gkhajduk.github.io/2017-03-09-mixed-models/)
- [`r fa("book-open", fill = ColorLinkInv)` Introduccion por Athanasia Mowinckel](https://athanasiamo.github.io/LME_introduction_workshop/slides/lme_rladies_london.html#1)<br>
- [`r fa("book-open", fill = ColorLinkInv)` Lectura sobre mixed-models with R Michel Clark](https://m-clark.github.io/mixed-models-with-R/#)

Videos en español
- [`r fa("youtube", fill = ColorLinkInv)` Modelos mixtos por Alejandra Tapia](https://alejandraandrea.github.io/slides-xaringan-mixed-models/#1)<br>

En ingles  
- [`r fa("youtube", fill = ColorLinkInv)` Video explicando TeoríaÑ Kyle Tomlinson](https://www.youtube.com/watch?v=sdYKtsmtXmc&list=PLVlVXU7jGfm1seY4xxINrsp23AmrYFYa7&index=4)


Imagenes
- Portada  
[Unsplash by Ilse Orsel](https://unsplash.com/@lgtts)  


---

name: repro
class: center, middle, inverse

# 1. Modelos lineares mixtos

---

## 1.1. Intro

Modelos lineales:  
- Errores aleatorios independientes
- Errores aleatorios siguen una distribución normal

Modelos lineales mixtos
- Incorpora efectos aleatorios para acomodar la correlación entre las observaciones 
- Condicionado a los efectos aleatorios, los errores aleatorios son independientes con  varianza constante 
- Errores aleatorios con distribución normal
- Efectos aleatorios con distribución normal 
- Efectos aleatorios y errores aleatorios son independientes 


---

## 1.1. Intro

¿Porque usarlos?

- Datos pueden presentar heterogeneidad
- Por ejemplo: pueden estar agrupados por provenir de diferentes áreas, o presentar medidas repetidas
- Medidas repetidas induce a una estructura de correlación, que si no se considera puede llevar a estimaciones sesgadas
- Afectando las predicciones y por lo tanto las decisiones basadas en esos datos


---
name: lmer

## 1.2. Datos

Paquetes a cargar para leer los datos
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)
library(dplyr)
library(here)
```

Cargar datos
```{r, message=FALSE}
url <- "https://raw.githubusercontent.com/alejandraandrea/slides-xaringan-mixed-models/master/dragons.tsv"
download.file(url, "dragons.tsv")
dragones <- read_tsv("dragons.tsv") #read_tsv de {readr}
```

---

## 1.2. Datos

Los datos contienen 480 observaciones contenidos en 4 columnas: testScore, bodyLenght, montainRange, site
```{r}
glimpse(dragones)
```

Antes de empezar cambiemos los nombres a español
```{r}
dragones<-dragones%>%
    rename(calificacion=testScore,
           tamanio = bodyLength,
           montania = mountainRange,
           sitio=site)
```

---

## 1.3. Preguntas

Imaginemos que:  
Se entrenaron dragones y se recopilaron datos de diferentes montañas.

.center[<h1>🐉💡</h1>]  

Entre mas rápido aprendieron el entrenamiento mejor calificación, también se midieron y se anoto en que sitio y en que región provienen.

.center[<h1>🐲💯</h1>] 

¿Afectara el tamaño de los dragones a sus calificaciones?


---

## 1.4. Inspeccionar datos

Creemos un gráfico de puntos
```{r,out.width="40%"}
dragones %>% 
  ggplot(aes(x=tamanio, 
             y=calificacion)) + 
             geom_jitter(alpha=.2)+
             theme_bw()
```


---

## 1.5 Ajustar modelo lineal

Cargar paquetes
```{r}
library(broom)
```

Ajustar un modelo lineal
```{r}
ajuste_lm <- lm(calificacion ~ tamanio, data=dragones)
```

Mirar estadísticos del modelo
```{r}
broom::tidy(ajuste_lm) %>% tibble::as_tibble()
```
¿Entre más grandes, más inteligentes?

---

## 1.5 Ajustar modelo lineal

Información sobre el modelo.
```{r}
glance(ajuste_lm) %>% 
  tibble::as_tibble()
```
Información sobre el ajuste del modelo.
```{r}
info_ajuste_lm<-augment_columns(ajuste_lm, dragones)
info_ajuste_lm
```

---

## 1.5 Modelo lineal

Gráfica el modelo lineal
```{r,out.width="40%"}
info_ajuste_lm %>% 
  ggplot(aes(x=tamanio,y=calificacion))+ 
  geom_jitter(alpha=.2)+
  geom_line(aes(x=tamanio,y=.fitted))+
  theme_bw()
```

---

## 1.6. Supuestos

Linealidad
```{r,out.width="40%"}
plot(ajuste_lm, which=1)
```

---

## 1.6. Supuestos
Normalidad
```{r,out.width="40%"}
plot(ajuste_lm, which=2)
```

---

## 1.6. Supuestos
Homocedasticidad
```{r,out.width="40%"}
plot(ajuste_lm, which=3)
```

---

## 1.7. Inspeccionar

Al graficar las montañas por separado. ¿Que notan?
```{r,out.width="40%"}
dragones %>%
  ggplot(aes(x=tamanio,y=calificacion, 
        colour=montania)) +
  geom_jitter(alpha=2) +
  theme_bw()
```

---

## 1.8. Inspeccionar

Separando por montañas. ¿Que notan?
```{r,out.width="30%"}
dragones %>% 
  ggplot(aes(tamanio,calificacion,
      colour = montania))+
  geom_jitter(alpha=2) + 
  facet_wrap(~ montania) +
  theme_bw()+
  theme(strip.background=element_rect(fill="white"))
```

---
name: random_effect

## 1.9. Efectos aleatorios

No se puede omitir la montaña , ¿pero como la incluimos?

- Como factor aleatorio.
- [`r fa("external-link-alt", fill = "#219ebc")` Que es un factor aleatorio y como saber cuando es aleatorio](https://dynamicecology.wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/)

Paquetes
```{r, message=FALSE, warning=FALSE}
library(broom.mixed)
library(lme4)
```

Sintaxis de los efectos aleatorios (random effects)
```{r}
ajuste_lmer <- lmer(calificacion ~ tamanio + 
                      (1|montania), data = dragones)
```

---

## 1.9. Efectos aleatorios

Mirar nuestro nuevo modelo.
```{r}
tidy(ajuste_lmer) %>% tibble::as_tibble()
```
Mirar los ajustes del modelo.
```{r}
glance(ajuste_lmer) %>% tibble::as_tibble()
```

**No hay valor p 💔😭**

---

## 1.9. Valor p

La libreria lmerTest te puede dar un valor p, pero no es muy útil y además no se reporta. 

```{r,message=FALSE, warning=FALSE}
library(lmerTest)
ajuste_lmer <- lmer(calificacion ~ tamanio + 
                      (1|montania), data = dragones)
tidy(ajuste_lmer) %>% tibble::as_tibble()
```

---

## 1.10. Efecto de la montaña

Ver información del ajuste: valores ajustados (.fitted), residuales (.resid)
```{r}
info_ajuste_lmer<- augment_columns(ajuste_lmer,dragones)
info_ajuste_lmer
```
Las montañas parecen tener un efecto en la calificación.

---

## 1.10. Efecto de la montaña

Veamos el efecto de las montañas en la calificación.
```{r,out.width="30%"}
info_ajuste_lmer %>% 
 ggplot(aes(x=tamanio,y=calificacion, colour=montania))+ 
 geom_jitter(alpha=2)+ 
 facet_wrap(~ montania)+
 geom_line(aes(x=tamanio,y=.fitted),
 colour="black")+
theme_bw()
```

---

## 1.11. Supuestos

```{r,out.width="30%"}
plot(ajuste_lmer)
```

---

## 1.11. Supuestos

```{r,out.width="30%"}
qqnorm(resid(ajuste_lmer))
qqline(resid(ajuste_lmer))
```

---

## 1.11. Modelo mixto

Ver ajustes del modelo mixto que incluye **montañas**
```{r,out.width="30%"}
summary(ajuste_lmer)
```

---

## 1.11. Modelo mixto

Se ve que la varianza de el sistema montañoso es 339.7.
Entonces las montañas son claramente importantes porque explican mucha de la variación. Como saber cuanto explican de la variación? Se puede tomar la varianza de la montaña y dividirla por el total de la varianza. 

```{r}
339.7/(339.7 + 223.8)
```


---
name: AIC
class: title-slide,center, middle, inverse

# 2. AIC

---

## 2.1. AIC

El AIC (Akaike Information criterion) es un modelo matemático para evaluar que tan bien se ajusta el modelo a los datos generados. En estadistica se usa mucho para comparar modelos posibles y determinar cual es el mejor modelo.

AIC se calcula de:
- El numero de variables independientes que se usó para construir el modelo
- El estimado de máxima verosimilitud (maximum likelihood), (que tan bien el modelo reproduce los datos)

El mejor modelo se identifica a partir de un AIC, que explica la mayor cantidad de variacion usando el menos numero de variables independientes. 

---

## 2.1. AIC

.center[<h1>🐉💡</h1>]  

Usando el ejemplo de dragones, que modelo se ajusta mejor a nuestros datos?
A lo mejor colectamos variables que no son importantes para nuestro modelo.

Consideren: los AIC menores son mejores, y AIC penaliza los modelos que usen más parámetros.

---
name: nested_effects

## 2.1. Efectos aleatorios anidados

En nuestros datos de dragones.

La variable de sitio es un factor con tres niveles: un sitio a, b y c. Y existe un anidamiento (nesting) del sitio con la montaña.  
Entonces los sitios no tienen significado si no le asignamos las montañas. 

Para no tener que estar recordando que esto ocurre, lo mejor es crear una nueva variable anidada (nested)

```{r}
dragones$muestra <- factor(paste0(dragones$montania,
                                  dragones$sitio))
```

**Recordando** el factor aleatorio solo aparece en un nivel en particular.  
Por eso es anidado, cada sitio pertenece a un sistema montañoso en especial y solo en ese sistema.  
Para efectos cruzados es cuando el factor aparece en más de un nivel en otros factores, por ejemplo si el mismo dragón aparece en más de un sistema montañoso.

---

## 2.2. Factores aleatorios

De acuerdo a lo que vimos anteriormente, entonces no podemos poner los efectos aleatorios separados.
```{r}
modelo_incorrecto <- lmer(calificacion ~ tamanio + 
                      (1|montania) + (1|sitio), data = dragones)  
```
Este modelo trata los efectos aleatorios como cruzados.
**Recuerden** que depende de su modelo y muestreo cual elegir. 

---

## 2.3. Modelo completo

Con los datos de dragones, una manera de crear un modelo completo sería la siguiente.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio + (1|montania) + (1|muestra), 
				  data = dragones, REML = FALSE)
```

```{r}
lmer_completo
```

---

## 2.4. Reportar el modelo

¿Como se reporta eso?

De mejor a peor lo que podemos hacer es usar:

- Z-test de Wald 
- t-test de Wald (en este modelo los valores tendrian que estar balanceados)
- **Prueba de razón de verosimilitud** (en inglés: Likelihood ratio tests).  
Usando anova() o drop1())
- Markov chain Monte Carlo (MCMC) o un bootstramp parametrico con intervalos de confianza

---


## 2.5. Compara modelos

Modelo completo.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio + 
                        (1|montania) + (1|muestra),
                      data = dragones, REML = FALSE)
```

Modelo reducido. **Nota** que este modelo no incluye tamaño.
```{r}
lmer_reducido <- lmer(calificacion ~ 1 + 
                        (1|montania) + (1|muestra), 
                      data = dragones, REML = FALSE)
```

Comparación de los modelos. 
```{r, eval=FALSE}
anova(lmer_reducido, lmer_completo) 
```

---

## 2.5. Compara modelos

Comparación de los modelos. Los modelos no son significativamente diferentes.   Tamaño no ayuda a explicar la calificación de los dragones.
```{r}
anova(lmer_reducido, lmer_completo)  
```

---

## 2.6. Más factores

Si tuvieramos mayor cantidad de variables, el modelo se crearía de otra forma.

Intentemos incrementar la complejidad, al generar valores aleatorios
```{r}
set.seed(1234)
edad<-runif(480, min=0, max=100)
set.seed(1234)
fuego<-runif(480, min=0, max=15)
```

Agregar como variables
```{r}
dragones$edad<-edad
dragones$fuego<-fuego
```

Cargar paquetes
```{r}
library(lme4)
library(MuMIn)
```

---

## 2.8. Comparar muchos modelos

Una manera de comprar modelos cuando tenemos muchas variables es crear varios modelos.

Primer modelo
```{r}
mod1 <- lmer(calificacion ~ tamanio + (1|montania) + (1|muestra), 
				  data = dragones, REML = FALSE)
```

Segundo modelo
```{r}
mod2 <- lmer(calificacion ~ tamanio + fuego + (1|montania) + (1|muestra), 
					     data = dragones, REML = FALSE)
```

Tercer modelo
```{r}
mod3 <- lmer(calificacion ~ tamanio + fuego + edad + (1|montania) + (1|muestra),data = dragones, REML = FALSE)
```

---

## 2.7. drop1

Otra manera de comparar modelos es usando **drop1**

Hay que crear el modelo completo.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio + edad + fuego +
                        (1|montania) + (1|muestra), 
				  data = dragones, REML = FALSE)
```

Esta función te sugiere como reducir tu modelo.
```{r}
drop1(lmer_completo, test="F")
```

---

## 2.9. Comparar muchos modelos

Otra manera es generar un modelo completo y usar la función **dredge**.  
Esta función sirve para evaluar que factores se pueden sacar del modelo para simplificarlo.

```{r}
library(MuMIn)
options(na.action = "na.fail")
```

```{r}
lmer_completo <- lmer(calificacion ~ tamanio +
                        (1|montania) + (1|muestra), 
                      data = dragones, REML = FALSE)
```

```{r, eval=FALSE}
dredge(lmer_completo)
```

---

## 2.9. Comparar muchos modelos

- **AICc**: Valores AIC para muestras pequeñas
- **delta**: diferencia entre modelos. Por convención AIC<2 se consideran modelos posibles.
-**weight**: Peso del modelo.

Todos estos valores pueden reportarse.

```{r}
dredge(lmer_completo)
```

---

# 3. Para considerar

- [Usar Machine learning](https://github.com/m-clark/introduction-to-machine-learning)

- [Usar estadistica bayesiana](https://oliviergimenez.github.io/blog/bayesworkshop/)

Otras lecturas:
- [El reinado de los valores p se ha terminado, ahora que hacemos?](https://royalsocietypublishing.org/doi/10.1098/rsbl.2019.0174)


---

class: left, inverse

# Contacto

Recapitulando

- [Modelos mixtos](#lmer)
- [Incluir efectos aleatorios](#random_effects)
- [Incluir efectos anidados](#nested_effects)
- [AIC](#AIC)
- [Comparar modelos](#comparar)
<br>
<br>

Para dudas, comentarios y sugerencias:  
- Escríbeme a miriamjlerma@gmail.com

<br>
<br>

.right[Este material esta accesible y se encuentra en <br>
mi [`r fa("external-link-alt", fill = ColorLinkInv)`github](https://github.com/MiriamLL/Curso_CIAD/)
y mi [`r fa("external-link-alt", fill = ColorLinkInv)`página](https://www.miriam-lerma.com/posts/2021-03-01-introar/)


.center[
```{r, echo=FALSE}
library(fontawesome)
```
<h3>`r fa("home", fill = ColorLinkInv)`[Volver ](https://www.miriam-lerma.com/posts/2021-03-01-introar/)
]]

